{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets , transforms\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()   # gpu is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3,[0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\"data/train\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 836\n",
       "    Root location: data/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(150, 150), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "           )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\"data/val\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_layers = nn.Sequential(\n",
    "    \n",
    "        nn.Conv2d(3,32,3), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32,64,3), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(64,128,3), nn.ReLU(), nn.MaxPool2d(2)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    dummy_input = torch.randn(1,3,150,150)\n",
    "    dummy_output = con_layers(dummy_input)\n",
    "    flatten_dim = dummy_output.view(1,-1).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    con_layers,\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(flatten_dim,256),nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256,1),\n",
    "    nn.Sigmoid()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m,nn.Conv2d) or isinstance(m,nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Linear(in_features=36992, out_features=256, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Dropout(p=0.3, inplace=False)\n",
       "  (5): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (6): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9528599977493286\n",
      "1 31.52790081501007\n",
      "1 67.03620541095734\n",
      "1 104.53620541095734\n",
      "1 173.28620541095734\n",
      "1 210.78620541095734\n",
      "1 260.78620541095734\n",
      "1 304.53620541095734\n",
      "1 354.53620541095734\n",
      "1 423.28620541095734\n",
      "1 454.53620541095734\n",
      "1 498.28620541095734\n",
      "1 517.0362054109573\n",
      "1 560.7862054109573\n",
      "1 592.0362054109573\n",
      "1 629.5362054109573\n",
      "1 679.5362054109573\n",
      "1 735.7862054109573\n",
      "1 754.5362054109573\n",
      "1 792.0362054109573\n",
      "1 829.5362054109573\n",
      "1 867.0362054109573\n",
      "1 898.2862054109573\n",
      "1 942.0362054109573\n",
      "1 992.0362054109573\n",
      "1 1054.5362054109573\n",
      "1 1085.7862054109573\n",
      "1 1160.7862054109573\n",
      "1 1192.0362054109573\n",
      "1 1254.5362054109573\n",
      "1 1292.0362054109573\n",
      "1 1342.0362054109573\n",
      "1 1367.0362054109573\n",
      "1 1423.2862054109573\n",
      "1 1460.7862054109573\n",
      "1 1510.7862054109573\n",
      "1 1548.2862054109573\n",
      "1 1598.2862054109573\n",
      "1 1629.5362054109573\n",
      "1 1679.5362054109573\n",
      "1 1704.5362054109573\n",
      "1 1742.0362054109573\n",
      "1 1785.7862054109573\n",
      "1 1842.0362054109573\n",
      "1 1910.7862054109573\n",
      "1 1985.7862054109573\n",
      "1 2029.5362054109573\n",
      "1 2079.5362054109573\n",
      "1 2117.0362054109573\n",
      "1 2167.0362054109573\n",
      "1 2210.7862054109573\n",
      "1 2248.2862054109573\n",
      "1 2348.2862054109573\n",
      "2 56.25\n",
      "2 100.0\n",
      "2 150.0\n",
      "2 200.0\n",
      "2 237.5\n",
      "2 293.75\n",
      "2 337.5\n",
      "2 375.0\n",
      "2 425.0\n",
      "2 481.25\n",
      "2 550.0\n",
      "2 593.75\n",
      "2 631.25\n",
      "2 681.25\n",
      "2 718.75\n",
      "2 768.75\n",
      "2 837.5\n",
      "2 881.25\n",
      "2 912.5\n",
      "2 925.0\n",
      "2 962.5\n",
      "2 993.75\n",
      "2 1012.5\n",
      "2 1062.5\n",
      "2 1093.75\n",
      "2 1143.75\n",
      "2 1168.75\n",
      "2 1218.75\n",
      "2 1250.0\n",
      "2 1306.25\n",
      "2 1356.25\n",
      "2 1418.75\n",
      "2 1481.25\n",
      "2 1525.0\n",
      "2 1562.5\n",
      "2 1618.75\n",
      "2 1656.25\n",
      "2 1706.25\n",
      "2 1731.25\n",
      "2 1787.5\n",
      "2 1843.75\n",
      "2 1893.75\n",
      "2 1937.5\n",
      "2 1956.25\n",
      "2 2006.25\n",
      "2 2050.0\n",
      "2 2087.5\n",
      "2 2131.25\n",
      "2 2181.25\n",
      "2 2225.0\n",
      "2 2275.0\n",
      "2 2306.25\n",
      "2 2356.25\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(2):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs ,labels in train_loader:\n",
    "        inputs,labels = inputs.to(device),labels.float().to(device).view(-1,1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        print(epochs +1 , total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"name.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
